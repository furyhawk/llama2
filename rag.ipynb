{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.embeddings import LlamaCppEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../../models/zephyr-7b-beta.Q8_0.gguf (version unknown)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.2.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:            blk.2.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:              blk.2.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:         blk.2.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:              blk.2.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:              blk.2.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:            blk.3.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:              blk.3.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:            blk.4.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:            blk.4.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:              blk.4.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:         blk.4.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:              blk.4.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:              blk.4.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:            blk.5.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:            blk.5.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:              blk.5.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:         blk.5.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:              blk.5.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:              blk.5.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:            blk.6.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:            blk.6.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:              blk.6.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:         blk.6.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:              blk.6.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:              blk.6.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:            blk.7.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:            blk.7.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:              blk.7.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:         blk.7.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.7.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:              blk.7.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:         blk.8.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:              blk.8.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:           blk.10.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:           blk.10.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.10.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:             blk.10.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:        blk.10.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:             blk.10.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.10.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:           blk.11.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:           blk.11.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.11.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.11.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:        blk.11.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.11.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.11.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.12.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.12.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:             blk.12.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:        blk.12.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.12.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.12.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:            blk.8.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.8.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:              blk.8.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:            blk.9.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:            blk.9.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.9.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:              blk.9.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:         blk.9.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:              blk.9.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.9.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.13.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.13.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.13.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.13.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.13.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.13.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.14.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.14.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.14.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.14.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.14.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.14.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.15.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.15.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.15.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.15.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.15.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:        blk.17.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.21.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:             blk.21.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:        blk.26.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32     \n",
      "llama_model_loader: - kv  20:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_print_meta: format           = unknown\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q8_0\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 7.17 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name   = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token = 2 '</s>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: mem required  = 7338.73 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  256.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 161.88 MB\n",
      "llama_new_context_with_model: max tensor size =   132.81 MB\n",
      "ggml_metal_add_buffer: allocated 'data            ' buffer, size =  7339.34 MB, ( 7339.97 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'kv              ' buffer, size =   258.00 MB, ( 7597.97 / 10922.67)\n",
      "ggml_metal_add_buffer: allocated 'alloc           ' buffer, size =   156.02 MB, ( 7753.98 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of RAM of your Apple Silicon Chip.\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "# llama_model_path = \"../../models/zephyr-7b-beta.Q4_K_M.gguf\"\n",
    "llama_model_path = \"../../models/zephyr-7b-beta.Q8_0.gguf\"\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=llama_model_path,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    n_ctx=2048,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../../models/zephyr-7b-beta.Q8_0.gguf (version unknown)\n",
      "llama_model_loader: - tensor    0:                token_embd.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor    1:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    2:            blk.0.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    3:            blk.0.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    4:              blk.0.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor    5:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor    6:              blk.0.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor    7:         blk.0.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    8:              blk.0.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor    9:              blk.0.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   10:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   11:            blk.1.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   12:            blk.1.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   13:              blk.1.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   14:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   15:              blk.1.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   16:         blk.1.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   17:              blk.1.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   18:              blk.1.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   19:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   20:            blk.2.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   21:            blk.2.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   22:              blk.2.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   23:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   24:              blk.2.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   25:         blk.2.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   26:              blk.2.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   27:              blk.2.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   28:            blk.3.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   29:              blk.3.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   30:              blk.3.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   31:         blk.3.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   32:              blk.3.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   33:              blk.3.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   34:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   35:            blk.3.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   36:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   37:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   38:            blk.4.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   39:            blk.4.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   40:              blk.4.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   41:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   42:              blk.4.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   43:         blk.4.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   44:              blk.4.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   45:              blk.4.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   46:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   47:            blk.5.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   48:            blk.5.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   49:              blk.5.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   50:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   51:              blk.5.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   52:         blk.5.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   53:              blk.5.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   54:              blk.5.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   55:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   56:            blk.6.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   57:            blk.6.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   58:              blk.6.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   59:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   60:              blk.6.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   61:         blk.6.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   62:              blk.6.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   63:              blk.6.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   64:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   65:            blk.7.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   66:            blk.7.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   67:              blk.7.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   68:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   69:              blk.7.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   70:         blk.7.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   71:              blk.7.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   72:              blk.7.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   73:              blk.8.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   74:         blk.8.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   75:              blk.8.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   76:              blk.8.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   77:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   78:           blk.10.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   79:           blk.10.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   80:             blk.10.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   81:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   82:             blk.10.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   83:        blk.10.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   84:             blk.10.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   85:             blk.10.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   86:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   87:           blk.11.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   88:           blk.11.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   89:             blk.11.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   90:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor   91:             blk.11.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   92:        blk.11.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   93:             blk.11.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   94:             blk.11.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   95:           blk.12.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   96:             blk.12.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor   97:             blk.12.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor   98:        blk.12.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor   99:             blk.12.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  100:             blk.12.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  101:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  102:            blk.8.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  103:            blk.8.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  104:              blk.8.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  105:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  106:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  107:            blk.9.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  108:            blk.9.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  109:              blk.9.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  110:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  111:              blk.9.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  112:         blk.9.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  113:              blk.9.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  114:              blk.9.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  115:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  116:           blk.12.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  117:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  118:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  119:           blk.13.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  120:           blk.13.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  121:             blk.13.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  122:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  123:             blk.13.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  124:        blk.13.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  125:             blk.13.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  126:             blk.13.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  127:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  128:           blk.14.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  129:           blk.14.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  130:             blk.14.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  131:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  132:             blk.14.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  133:        blk.14.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  134:             blk.14.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  135:             blk.14.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  136:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  137:           blk.15.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  138:           blk.15.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  139:             blk.15.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  140:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  141:             blk.15.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  142:        blk.15.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  143:             blk.15.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  144:             blk.15.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  145:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  146:           blk.16.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  147:           blk.16.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  148:             blk.16.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  149:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  150:             blk.16.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  151:        blk.16.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  152:             blk.16.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  153:             blk.16.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  154:             blk.17.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  155:        blk.17.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  156:             blk.17.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  157:             blk.17.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  158:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  159:           blk.17.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  160:           blk.17.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  161:             blk.17.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  162:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  163:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  164:           blk.18.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  165:           blk.18.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  166:             blk.18.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  167:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  168:             blk.18.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  169:        blk.18.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  170:             blk.18.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  171:             blk.18.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  172:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  173:           blk.19.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  174:           blk.19.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  175:             blk.19.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  176:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  177:             blk.19.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  178:        blk.19.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  179:             blk.19.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  180:             blk.19.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  181:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  182:           blk.20.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  183:           blk.20.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  184:             blk.20.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  185:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  186:             blk.20.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  187:        blk.20.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  188:             blk.20.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  189:             blk.20.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  190:           blk.21.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  191:             blk.21.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  192:             blk.21.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  193:        blk.21.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  194:             blk.21.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  195:             blk.21.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  196:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  197:           blk.21.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  198:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  199:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  200:           blk.22.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  201:           blk.22.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  202:             blk.22.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  203:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  204:             blk.22.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  205:        blk.22.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  206:             blk.22.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  207:             blk.22.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  208:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  209:           blk.23.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  210:           blk.23.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  211:             blk.23.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  212:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  213:             blk.23.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  214:        blk.23.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  215:             blk.23.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  216:             blk.23.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  217:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  218:           blk.24.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  219:           blk.24.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  220:             blk.24.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  221:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  222:             blk.24.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  223:        blk.24.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  224:             blk.24.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  225:             blk.24.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  226:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  227:           blk.25.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  228:           blk.25.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  229:             blk.25.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  230:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  231:             blk.25.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  232:        blk.25.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  233:             blk.25.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  234:             blk.25.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  235:             blk.26.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  236:        blk.26.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  237:             blk.26.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  238:             blk.26.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  239:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  240:           blk.26.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  241:           blk.26.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  242:             blk.26.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  243:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  244:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  245:           blk.27.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  246:           blk.27.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  247:             blk.27.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  248:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  249:             blk.27.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  250:        blk.27.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  251:             blk.27.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  252:             blk.27.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  253:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  254:           blk.28.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  255:           blk.28.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  256:             blk.28.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  257:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  258:             blk.28.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  259:        blk.28.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  260:             blk.28.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  261:             blk.28.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  262:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  263:           blk.29.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  264:           blk.29.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  265:             blk.29.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  266:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  267:             blk.29.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  268:        blk.29.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  269:             blk.29.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  270:             blk.29.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  271:           blk.30.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  272:             blk.30.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  273:             blk.30.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  274:        blk.30.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  275:             blk.30.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  276:             blk.30.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  277:                    output.weight q8_0     [  4096, 32000,     1,     1 ]\n",
      "llama_model_loader: - tensor  278:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  279:           blk.30.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  280:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  281:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  282:           blk.31.ffn_down.weight q8_0     [ 14336,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  283:           blk.31.ffn_gate.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  284:             blk.31.ffn_up.weight q8_0     [  4096, 14336,     1,     1 ]\n",
      "llama_model_loader: - tensor  285:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - tensor  286:             blk.31.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  287:        blk.31.attn_output.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  288:             blk.31.attn_q.weight q8_0     [  4096,  4096,     1,     1 ]\n",
      "llama_model_loader: - tensor  289:             blk.31.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
      "llama_model_loader: - tensor  290:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
      "llama_model_loader: - kv   0:                       general.architecture str     \n",
      "llama_model_loader: - kv   1:                               general.name str     \n",
      "llama_model_loader: - kv   2:                       llama.context_length u32     \n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32     \n",
      "llama_model_loader: - kv   4:                          llama.block_count u32     \n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32     \n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32     \n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32     \n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32     \n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32     \n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32     \n",
      "llama_model_loader: - kv  11:                          general.file_type u32     \n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str     \n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr     \n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr     \n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr     \n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32     \n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32     \n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32     \n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32     \n",
      "llama_model_loader: - kv  20:               general.quantization_version u32     \n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q8_0:  226 tensors\n",
      "llm_load_print_meta: format           = unknown\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = mostly Q8_0\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 7.17 GiB (8.50 BPW) \n",
      "llm_load_print_meta: general.name   = huggingfaceh4_zephyr-7b-beta\n",
      "llm_load_print_meta: BOS token = 1 '<s>'\n",
      "llm_load_print_meta: EOS token = 2 '</s>'\n",
      "llm_load_print_meta: UNK token = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token = 2 '</s>'\n",
      "llm_load_print_meta: LF token  = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.09 MB\n",
      "llm_load_tensors: mem required  = 7338.73 MB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 2048\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: kv self size  =  512.00 MB\n",
      "llama_new_context_with_model: compute buffer total size = 8.31 MB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "#Use Llama model for embedding\n",
    "embeddings = LlamaCppEmbeddings(model_path=llama_model_path, n_ctx=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Mercury, 2) Venus, 3) Earth, 4) Mars, 5) Jupiter, 6) Saturn"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =    41.42 ms /    32 runs   (    1.29 ms per token,   772.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =  8039.95 ms /    14 tokens (  574.28 ms per token,     1.74 tokens per second)\n",
      "llama_print_timings:        eval time =  1491.02 ms /    31 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_print_timings:       total time =  9666.30 ms\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, stop=[\"Q:\", \"\\n\"], echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) Mercury, 2) Venus, 3) Earth, 4) Mars, 5) Jupiter, 6) Saturn'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   554.17 ms /     8 tokens (   69.27 ms per token,    14.44 tokens per second)\n",
      "llama_print_timings:        eval time =    91.74 ms /     1 runs   (   91.74 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =   648.38 ms\n"
     ]
    }
   ],
   "source": [
    "vectorstore = FAISS.from_texts([\"harrison worked at kensho\"], embedding=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | model \n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   338.67 ms /     8 tokens (   42.33 ms per token,    23.62 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   339.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Assistant: Harrison worked at Kensho.\n",
      "\n",
      "Note: This example assumes that the provided \"document\" or context is a real-life scenario where Harrison's employment history is being documented, and we are only looking for his place of work during the timeframe in question. If there is any ambiguity or uncertainty about whether this specific document accurately reflects Harrison's entire employment history, further context or clarification may be required to answer the question definitively."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =    80.39 ms /    97 runs   (    0.83 ms per token,  1206.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =   444.40 ms /    42 tokens (   10.58 ms per token,    94.51 tokens per second)\n",
      "llama_print_timings:        eval time =  4704.71 ms /    96 runs   (   49.01 ms per token,    20.41 tokens per second)\n",
      "llama_print_timings:       total time =  5412.42 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nAssistant: Harrison worked at Kensho.\\n\\nNote: This example assumes that the provided \"document\" or context is a real-life scenario where Harrison\\'s employment history is being documented, and we are only looking for his place of work during the timeframe in question. If there is any ambiguity or uncertainty about whether this specific document accurately reflects Harrison\\'s entire employment history, further context or clarification may be required to answer the question definitively.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"where did harrison work?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer in the following language: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = {\n",
    "    \"context\": itemgetter(\"question\") | retriever, \n",
    "    \"question\": itemgetter(\"question\"), \n",
    "    \"language\": itemgetter(\"language\")\n",
    "} | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   287.42 ms /     7 tokens (   41.06 ms per token,    24.35 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   288.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Humano: Rispondi alla domanda solo a partire dal contesto seguente:\n",
      "[Documento(contenuto_pagina='harrison lavorò in kensho')]\n",
      "\n",
      "Domanda: dove ha lavorato harryson\n",
      "\n",
      "Risposta nella seguente lingua: italiano"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =    54.73 ms /    70 runs   (    0.78 ms per token,  1278.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =   157.80 ms /    12 tokens (   13.15 ms per token,    76.04 tokens per second)\n",
      "llama_print_timings:        eval time =  3405.13 ms /    69 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_print_timings:       total time =  3744.03 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nHumano: Rispondi alla domanda solo a partire dal contesto seguente:\\n[Documento(contenuto_pagina='harrison lavorò in kensho')]\\n\\nDomanda: dove ha lavorato harryson\\n\\nRisposta nella seguente lingua: italiano\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"where did harrison work\", \"language\": \"italian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ","
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " each using facts and statistics to support their arguments on social justice issues. The battle should include at least three rounds with each comedian presenting a new issue in each round, and there should be a live audience reacting to the performances. The style of the battle should be fast-paced, humorous, and politically charged. Bonus points for incorporating musical elements such as beats or samples."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =    99.90 ms /    84 runs   (    1.19 ms per token,   840.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =   143.97 ms /    12 tokens (   12.00 ms per token,    83.35 tokens per second)\n",
      "llama_print_timings:        eval time =  4057.81 ms /    83 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_print_timings:       total time =  4528.58 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "', each using facts and statistics to support their arguments on social justice issues. The battle should include at least three rounds with each comedian presenting a new issue in each round, and there should be a live audience reacting to the performances. The style of the battle should be fast-paced, humorous, and politically charged. Bonus points for incorporating musical elements such as beats or samples.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Simulate a rap battle between Stephen Colbert and John Oliver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "data = loader.load()\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time = 11233.24 ms /   240 tokens (   46.81 ms per token,    21.37 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time = 11266.14 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1510.37 ms /    38 tokens (   39.75 ms per token,    25.16 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1515.76 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4772.81 ms /   120 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =    82.03 ms /     1 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =  4871.11 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3104.53 ms /    78 tokens (   39.80 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3114.35 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3072.26 ms /    77 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3083.13 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1938.68 ms /    48 tokens (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1944.89 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2079.70 ms /    52 tokens (   39.99 ms per token,    25.00 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2086.63 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3630.77 ms /    91 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3643.11 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3634.59 ms /    91 tokens (   39.94 ms per token,    25.04 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3646.50 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3005.16 ms /    75 tokens (   40.07 ms per token,    24.96 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3015.22 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5046.45 ms /   126 tokens (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5062.36 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1927.85 ms /    48 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =    83.67 ms /     1 runs   (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =  2018.07 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2071.97 ms /    52 tokens (   39.85 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2078.97 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5024.16 ms /   112 tokens (   44.86 ms per token,    22.29 tokens per second)\n",
      "llama_print_timings:        eval time =    83.00 ms /     1 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =  5122.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   314.54 ms /     8 tokens (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   315.12 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3839.92 ms /    96 tokens (   40.00 ms per token,    25.00 tokens per second)\n",
      "llama_print_timings:        eval time =    82.17 ms /     1 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =  3935.20 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4567.40 ms /   115 tokens (   39.72 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4583.31 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   593.64 ms /    15 tokens (   39.58 ms per token,    25.27 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   595.50 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3842.04 ms /    96 tokens (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3854.26 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2732.73 ms /    67 tokens (   40.79 ms per token,    24.52 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2742.24 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2081.29 ms /    50 tokens (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2088.67 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6508.98 ms /   160 tokens (   40.68 ms per token,    24.58 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6530.23 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5479.19 ms /   134 tokens (   40.89 ms per token,    24.46 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5497.44 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3741.15 ms /    91 tokens (   41.11 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3753.79 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1868.70 ms /    46 tokens (   40.62 ms per token,    24.62 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1874.43 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4672.39 ms /   115 tokens (   40.63 ms per token,    24.61 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4687.94 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1965.37 ms /    48 tokens (   40.95 ms per token,    24.42 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1971.96 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1484.48 ms /    37 tokens (   40.12 ms per token,    24.92 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1489.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3826.09 ms /    95 tokens (   40.27 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3838.74 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2841.02 ms /    71 tokens (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2850.28 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4782.31 ms /   118 tokens (   40.53 ms per token,    24.67 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4798.38 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   450.74 ms /    11 tokens (   40.98 ms per token,    24.40 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   452.62 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5034.02 ms /   124 tokens (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5050.57 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1235.10 ms /    31 tokens (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1238.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3288.48 ms /    82 tokens (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3299.98 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5086.83 ms /   120 tokens (   42.39 ms per token,    23.59 tokens per second)\n",
      "llama_print_timings:        eval time =    82.84 ms /     1 runs   (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =  5185.75 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4395.85 ms /   110 tokens (   39.96 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4409.98 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3212.27 ms /    79 tokens (   40.66 ms per token,    24.59 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3222.28 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3956.67 ms /    99 tokens (   39.97 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3970.19 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   558.10 ms /    14 tokens (   39.86 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   559.86 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2024.48 ms /    50 tokens (   40.49 ms per token,    24.70 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2031.43 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4389.34 ms /   110 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4403.57 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   525.35 ms /    13 tokens (   40.41 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   527.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4555.80 ms /   114 tokens (   39.96 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4570.91 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2425.10 ms /    61 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2433.41 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3629.22 ms /    91 tokens (   39.88 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3641.78 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3818.01 ms /    96 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =    83.09 ms /     1 runs   (   83.09 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =  3913.90 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4123.18 ms /   104 tokens (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:        eval time =    82.75 ms /     1 runs   (   82.75 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =  4220.19 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2162.91 ms /    54 tokens (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2169.60 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4674.76 ms /   117 tokens (   39.96 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4690.21 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4332.73 ms /   107 tokens (   40.49 ms per token,    24.70 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4347.65 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3741.44 ms /    94 tokens (   39.80 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3753.88 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4454.36 ms /   112 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =    83.31 ms /     1 runs   (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =  4553.58 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4243.80 ms /   106 tokens (   40.04 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4257.91 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5139.42 ms /   128 tokens (   40.15 ms per token,    24.91 tokens per second)\n",
      "llama_print_timings:        eval time =    82.66 ms /     1 runs   (   82.66 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =  5239.22 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3156.31 ms /    79 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3166.05 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2466.73 ms /    62 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2474.99 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3936.05 ms /    98 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3949.58 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   871.03 ms /    22 tokens (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   874.33 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4288.55 ms /   106 tokens (   40.46 ms per token,    24.72 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4302.89 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   485.05 ms /    12 tokens (   40.42 ms per token,    24.74 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   486.36 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3948.18 ms /    98 tokens (   40.29 ms per token,    24.82 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3961.88 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5061.09 ms /   126 tokens (   40.17 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5077.69 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   929.99 ms /    23 tokens (   40.43 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   932.66 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2893.54 ms /    72 tokens (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:        eval time =    82.34 ms /     1 runs   (   82.34 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =  2986.09 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3475.34 ms /    87 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3486.39 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3347.73 ms /    83 tokens (   40.33 ms per token,    24.79 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3359.29 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2241.25 ms /    56 tokens (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2247.69 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4116.31 ms /   102 tokens (   40.36 ms per token,    24.78 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4129.94 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2814.83 ms /    70 tokens (   40.21 ms per token,    24.87 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2823.66 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4049.96 ms /   100 tokens (   40.50 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4063.15 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   322.47 ms /     8 tokens (   40.31 ms per token,    24.81 tokens per second)\n",
      "llama_print_timings:        eval time =    84.58 ms /     1 runs   (   84.58 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =   409.22 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3855.64 ms /    96 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =    83.50 ms /     1 runs   (   83.50 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =  3951.83 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1936.57 ms /    46 tokens (   42.10 ms per token,    23.75 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1942.97 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4266.77 ms /   107 tokens (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4280.84 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3284.29 ms /    82 tokens (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3295.24 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1503.59 ms /    38 tokens (   39.57 ms per token,    25.27 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1508.44 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3474.68 ms /    86 tokens (   40.40 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3486.37 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3838.05 ms /    96 tokens (   39.98 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =    83.42 ms /     1 runs   (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =  3934.90 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2472.85 ms /    62 tokens (   39.88 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2480.60 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3248.04 ms /    80 tokens (   40.60 ms per token,    24.63 tokens per second)\n",
      "llama_print_timings:        eval time =    82.39 ms /     1 runs   (   82.39 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =  3341.26 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3381.98 ms /    85 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3393.19 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4267.36 ms /   106 tokens (   40.26 ms per token,    24.84 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4281.65 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1236.04 ms /    31 tokens (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1239.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1701.55 ms /    42 tokens (   40.51 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1706.96 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4375.46 ms /   109 tokens (   40.14 ms per token,    24.91 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4389.99 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6707.42 ms /   167 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6729.55 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  7091.88 ms /   175 tokens (   40.53 ms per token,    24.68 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  7114.88 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6523.48 ms /   163 tokens (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6544.82 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   956.12 ms /    24 tokens (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   958.42 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1947.27 ms /    48 tokens (   40.57 ms per token,    24.65 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1953.04 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3544.06 ms /    88 tokens (   40.27 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3555.01 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5565.21 ms /   139 tokens (   40.04 ms per token,    24.98 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5583.08 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4395.20 ms /   109 tokens (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4409.17 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5458.90 ms /   135 tokens (   40.44 ms per token,    24.73 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5476.07 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5023.16 ms /   126 tokens (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5039.32 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4657.45 ms /   115 tokens (   40.50 ms per token,    24.69 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4673.32 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   457.25 ms /    11 tokens (   41.57 ms per token,    24.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   458.71 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4448.25 ms /   112 tokens (   39.72 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4462.06 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4333.61 ms /   108 tokens (   40.13 ms per token,    24.92 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4348.09 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4331.05 ms /   108 tokens (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4344.75 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3504.57 ms /    86 tokens (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3515.98 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3932.65 ms /    93 tokens (   42.29 ms per token,    23.65 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3945.41 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1400.38 ms /    34 tokens (   41.19 ms per token,    24.28 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1405.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   313.27 ms /     8 tokens (   39.16 ms per token,    25.54 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   313.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   799.65 ms /    19 tokens (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   802.21 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4534.57 ms /   112 tokens (   40.49 ms per token,    24.70 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4549.22 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5407.25 ms /   131 tokens (   41.28 ms per token,    24.23 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5424.63 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3966.08 ms /   100 tokens (   39.66 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3979.91 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4118.94 ms /   103 tokens (   39.99 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4132.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1401.14 ms /    34 tokens (   41.21 ms per token,    24.27 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1405.66 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1497.32 ms /    37 tokens (   40.47 ms per token,    24.71 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1501.95 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4347.07 ms /   109 tokens (   39.88 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4361.12 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   317.52 ms /     8 tokens (   39.69 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   318.28 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   524.95 ms /    13 tokens (   40.38 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   526.43 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4488.64 ms /   112 tokens (   40.08 ms per token,    24.95 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4503.21 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5013.62 ms /   126 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5029.65 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1469.28 ms /    37 tokens (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1474.29 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1476.27 ms /    37 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1481.56 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3502.06 ms /    88 tokens (   39.80 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3512.78 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   173.42 ms /     4 tokens (   43.36 ms per token,    23.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   174.02 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2149.86 ms /    54 tokens (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2157.24 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3823.70 ms /    96 tokens (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3835.79 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2219.91 ms /    56 tokens (   39.64 ms per token,    25.23 tokens per second)\n",
      "llama_print_timings:        eval time =    84.72 ms /     1 runs   (   84.72 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =  2312.31 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8109.24 ms /   203 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8135.27 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8766.31 ms /   218 tokens (   40.21 ms per token,    24.87 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8795.03 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  7198.75 ms /   179 tokens (   40.22 ms per token,    24.87 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  7222.84 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8520.80 ms /   212 tokens (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8547.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4382.32 ms /   110 tokens (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4395.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3502.66 ms /    88 tokens (   39.80 ms per token,    25.12 tokens per second)\n",
      "llama_print_timings:        eval time =    82.87 ms /     1 runs   (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =  3597.94 ms\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time = 18264.81 ms /   240 tokens (   76.10 ms per token,    13.14 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time = 18297.52 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1527.59 ms /    38 tokens (   40.20 ms per token,    24.88 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1533.79 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4838.91 ms /   120 tokens (   40.32 ms per token,    24.80 tokens per second)\n",
      "llama_print_timings:        eval time =    83.50 ms /     1 runs   (   83.50 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =  4939.60 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3118.62 ms /    78 tokens (   39.98 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3128.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3058.12 ms /    77 tokens (   39.72 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3068.07 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1928.06 ms /    48 tokens (   40.17 ms per token,    24.90 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1934.16 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2100.50 ms /    52 tokens (   40.39 ms per token,    24.76 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2107.96 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3626.35 ms /    91 tokens (   39.85 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3638.86 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3619.22 ms /    91 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3630.89 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2998.14 ms /    75 tokens (   39.98 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3008.10 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5006.97 ms /   126 tokens (   39.74 ms per token,    25.16 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5023.46 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1903.04 ms /    48 tokens (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_print_timings:        eval time =    84.11 ms /     1 runs   (   84.11 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =  1993.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2084.93 ms /    52 tokens (   40.09 ms per token,    24.94 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2091.99 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4427.56 ms /   112 tokens (   39.53 ms per token,    25.30 tokens per second)\n",
      "llama_print_timings:        eval time =    83.63 ms /     1 runs   (   83.63 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =  4526.47 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   311.63 ms /     8 tokens (   38.95 ms per token,    25.67 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   312.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3790.48 ms /    96 tokens (   39.48 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:        eval time =    83.59 ms /     1 runs   (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =  3887.55 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4598.15 ms /   115 tokens (   39.98 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4613.72 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   591.80 ms /    15 tokens (   39.45 ms per token,    25.35 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   593.61 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3800.06 ms /    96 tokens (   39.58 ms per token,    25.26 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3812.46 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2707.37 ms /    67 tokens (   40.41 ms per token,    24.75 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2716.36 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2090.76 ms /    50 tokens (   41.82 ms per token,    23.91 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2097.97 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6372.19 ms /   160 tokens (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6393.48 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5329.64 ms /   134 tokens (   39.77 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5346.82 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3640.12 ms /    91 tokens (   40.00 ms per token,    25.00 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3652.00 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1835.46 ms /    46 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1841.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4575.94 ms /   115 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4591.87 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1947.66 ms /    48 tokens (   40.58 ms per token,    24.64 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1953.84 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1480.33 ms /    37 tokens (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1485.69 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3776.97 ms /    95 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3789.65 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2802.51 ms /    71 tokens (   39.47 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2811.70 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4705.77 ms /   118 tokens (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4721.53 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   448.30 ms /    11 tokens (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   449.87 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4947.12 ms /   124 tokens (   39.90 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4963.28 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1222.64 ms /    31 tokens (   39.44 ms per token,    25.36 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1226.39 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3290.65 ms /    82 tokens (   40.13 ms per token,    24.92 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3301.24 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4725.36 ms /   120 tokens (   39.38 ms per token,    25.39 tokens per second)\n",
      "llama_print_timings:        eval time =    82.75 ms /     1 runs   (   82.75 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =  4824.05 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4344.95 ms /   110 tokens (   39.50 ms per token,    25.32 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4359.23 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3108.23 ms /    79 tokens (   39.34 ms per token,    25.42 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3117.70 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3921.65 ms /    99 tokens (   39.61 ms per token,    25.24 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3935.01 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   577.89 ms /    14 tokens (   41.28 ms per token,    24.23 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   579.66 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1985.90 ms /    50 tokens (   39.72 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1992.52 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4346.61 ms /   110 tokens (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4361.07 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   537.88 ms /    13 tokens (   41.38 ms per token,    24.17 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   539.81 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4527.06 ms /   114 tokens (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4541.66 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2406.99 ms /    61 tokens (   39.46 ms per token,    25.34 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2414.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3629.63 ms /    91 tokens (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3641.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3802.09 ms /    96 tokens (   39.61 ms per token,    25.25 tokens per second)\n",
      "llama_print_timings:        eval time =    86.45 ms /     1 runs   (   86.45 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =  3902.03 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4143.02 ms /   104 tokens (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =    81.94 ms /     1 runs   (   81.94 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =  4239.70 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2142.05 ms /    54 tokens (   39.67 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2148.70 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4667.62 ms /   117 tokens (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4683.12 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4304.36 ms /   107 tokens (   40.23 ms per token,    24.86 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4318.76 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3733.15 ms /    94 tokens (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3745.52 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4423.43 ms /   112 tokens (   39.49 ms per token,    25.32 tokens per second)\n",
      "llama_print_timings:        eval time =    84.57 ms /     1 runs   (   84.57 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =  4523.61 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4218.12 ms /   106 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4231.75 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5072.61 ms /   128 tokens (   39.63 ms per token,    25.23 tokens per second)\n",
      "llama_print_timings:        eval time =    83.24 ms /     1 runs   (   83.24 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =  5172.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3107.50 ms /    79 tokens (   39.34 ms per token,    25.42 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3117.97 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2439.85 ms /    62 tokens (   39.35 ms per token,    25.41 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2447.73 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3883.54 ms /    98 tokens (   39.63 ms per token,    25.23 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3896.26 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   865.01 ms /    22 tokens (   39.32 ms per token,    25.43 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   868.00 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4396.79 ms /   106 tokens (   41.48 ms per token,    24.11 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4411.60 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   492.03 ms /    12 tokens (   41.00 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   493.81 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3946.82 ms /    98 tokens (   40.27 ms per token,    24.83 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3960.51 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5303.27 ms /   126 tokens (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5319.80 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   924.21 ms /    23 tokens (   40.18 ms per token,    24.89 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   928.13 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2859.98 ms /    72 tokens (   39.72 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:        eval time =    83.25 ms /     1 runs   (   83.25 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =  2953.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3452.71 ms /    87 tokens (   39.69 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3464.29 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3310.87 ms /    83 tokens (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3321.88 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2218.55 ms /    56 tokens (   39.62 ms per token,    25.24 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2225.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4161.73 ms /   102 tokens (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4174.49 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2781.77 ms /    70 tokens (   39.74 ms per token,    25.16 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2790.91 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4001.16 ms /   100 tokens (   40.01 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4014.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   317.14 ms /     8 tokens (   39.64 ms per token,    25.23 tokens per second)\n",
      "llama_print_timings:        eval time =    82.61 ms /     1 runs   (   82.61 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =   401.52 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3812.09 ms /    96 tokens (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_print_timings:        eval time =    83.84 ms /     1 runs   (   83.84 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =  3909.26 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1825.24 ms /    46 tokens (   39.68 ms per token,    25.20 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1830.67 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4274.49 ms /   107 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4288.95 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3276.49 ms /    82 tokens (   39.96 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3287.70 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1524.21 ms /    38 tokens (   40.11 ms per token,    24.93 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1529.04 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3431.02 ms /    86 tokens (   39.90 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3442.37 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3816.30 ms /    96 tokens (   39.75 ms per token,    25.16 tokens per second)\n",
      "llama_print_timings:        eval time =    83.41 ms /     1 runs   (   83.41 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =  3912.69 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2472.49 ms /    62 tokens (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2480.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3173.13 ms /    80 tokens (   39.66 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:        eval time =    81.87 ms /     1 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =  3266.37 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3378.67 ms /    85 tokens (   39.75 ms per token,    25.16 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3389.76 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4359.11 ms /   106 tokens (   41.12 ms per token,    24.32 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4373.43 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1267.02 ms /    31 tokens (   40.87 ms per token,    24.47 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1271.35 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1718.08 ms /    42 tokens (   40.91 ms per token,    24.45 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1723.62 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4383.81 ms /   109 tokens (   40.22 ms per token,    24.86 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4397.96 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6643.83 ms /   167 tokens (   39.78 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6665.29 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6963.47 ms /   175 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6985.38 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  6511.82 ms /   163 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  6533.22 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   946.57 ms /    24 tokens (   39.44 ms per token,    25.35 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   948.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1898.12 ms /    48 tokens (   39.54 ms per token,    25.29 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1903.93 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3511.25 ms /    88 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3522.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5537.03 ms /   139 tokens (   39.83 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5554.62 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4347.86 ms /   109 tokens (   39.89 ms per token,    25.07 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4362.02 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5370.82 ms /   135 tokens (   39.78 ms per token,    25.14 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5387.48 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5020.42 ms /   126 tokens (   39.84 ms per token,    25.10 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5036.00 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4624.11 ms /   115 tokens (   40.21 ms per token,    24.87 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4639.06 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   450.66 ms /    11 tokens (   40.97 ms per token,    24.41 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   452.29 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4450.35 ms /   112 tokens (   39.74 ms per token,    25.17 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4464.37 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4293.55 ms /   108 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4307.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4318.80 ms /   108 tokens (   39.99 ms per token,    25.01 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4333.27 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3428.78 ms /    86 tokens (   39.87 ms per token,    25.08 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3439.82 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3700.36 ms /    93 tokens (   39.79 ms per token,    25.13 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3712.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1385.08 ms /    34 tokens (   40.74 ms per token,    24.55 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1390.40 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   314.01 ms /     8 tokens (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   314.80 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   819.91 ms /    19 tokens (   43.15 ms per token,    23.17 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   822.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4482.61 ms /   112 tokens (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4496.33 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  5221.25 ms /   131 tokens (   39.86 ms per token,    25.09 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  5238.03 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4135.46 ms /   100 tokens (   41.35 ms per token,    24.18 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4148.97 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4102.30 ms /   103 tokens (   39.83 ms per token,    25.11 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4115.48 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1364.04 ms /    34 tokens (   40.12 ms per token,    24.93 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1369.19 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1465.67 ms /    37 tokens (   39.61 ms per token,    25.24 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1470.54 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4304.29 ms /   109 tokens (   39.49 ms per token,    25.32 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4318.45 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   317.36 ms /     8 tokens (   39.67 ms per token,    25.21 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   317.56 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   532.99 ms /    13 tokens (   41.00 ms per token,    24.39 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   534.98 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4401.13 ms /   112 tokens (   39.30 ms per token,    25.45 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4414.77 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4959.97 ms /   126 tokens (   39.36 ms per token,    25.40 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4975.96 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1460.03 ms /    37 tokens (   39.46 ms per token,    25.34 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1465.34 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  1478.96 ms /    37 tokens (   39.97 ms per token,    25.02 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  1483.86 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3462.57 ms /    88 tokens (   39.35 ms per token,    25.41 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3473.55 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   177.14 ms /     4 tokens (   44.29 ms per token,    22.58 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   177.38 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2132.27 ms /    54 tokens (   39.49 ms per token,    25.33 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  2139.02 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3768.56 ms /    96 tokens (   39.26 ms per token,    25.47 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  3780.23 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  2198.88 ms /    56 tokens (   39.27 ms per token,    25.47 tokens per second)\n",
      "llama_print_timings:        eval time =    84.12 ms /     1 runs   (   84.12 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =  2291.16 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8031.12 ms /   203 tokens (   39.56 ms per token,    25.28 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8056.79 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8669.62 ms /   218 tokens (   39.77 ms per token,    25.15 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8698.03 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  7079.19 ms /   179 tokens (   39.55 ms per token,    25.29 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  7101.74 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  8399.24 ms /   212 tokens (   39.62 ms per token,    25.24 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  8426.00 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  4355.07 ms /   110 tokens (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =  4369.09 ms\n",
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =  3476.63 ms /    88 tokens (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_print_timings:        eval time =    83.10 ms /     1 runs   (   83.10 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =  3571.45 ms\n"
     ]
    }
   ],
   "source": [
    "# vectorstore = FAISS.from_documents(documents=all_splits, embedding=embeddings)\n",
    "# retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   489.99 ms /    11 tokens (   44.54 ms per token,    22.45 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   492.23 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='judge the correctness of task results.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='to start a new trial depending on the self-reflection results.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='(2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\\nInstruction:', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"}),\n",
       " Document(page_content='The design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.', metadata={'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en', 'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\"})]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   554.54 ms\n",
      "llama_print_timings:      sample time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings: prompt eval time =   647.44 ms /    11 tokens (   58.86 ms per token,    16.99 tokens per second)\n",
      "llama_print_timings:        eval time =     0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
      "llama_print_timings:       total time =   649.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Generate according to: Summarize the main themes in these retrieved docs: [Document(page_content='judge the correctness of task results.', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:', 'language': 'en'}), Document(page_content='to start a new trial depending on the self-reflection results.', metadata={'source': 'https://lilianweng.github.io/posts/"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =   341.39 ms /   256 runs   (    1.33 ms per token,   749.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =  4712.75 ms /   889 tokens (    5.30 ms per token,   188.64 tokens per second)\n",
      "llama_print_timings:        eval time = 13727.24 ms /   255 runs   (   53.83 ms per token,    18.58 tokens per second)\n",
      "llama_print_timings:       total time = 19605.33 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nGenerate according to: Summarize the main themes in these retrieved docs: [Document(page_content=\\'judge the correctness of task results.\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\', \\'title\\': \"LLM Powered Autonomous Agents | Lil\\'Log\", \\'description\\': \\'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\\\nAgent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\', \\'language\\': \\'en\\'}), Document(page_content=\\'to start a new trial depending on the self-reflection results.\\', metadata={\\'source\\': \\'https://lilianweng.github.io/posts/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"Summarize the main themes in these retrieved docs: {docs}\"\n",
    ")\n",
    "\n",
    "# Chain\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Run\n",
    "question = \"What are the approaches to Task Decomposition?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "result = llm_chain(docs)\n",
    "\n",
    "# Output\n",
    "result[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " To list all the text files (i.e., files with extension .txt) in the current directory that have been modified within the last 30 days, you can use the `find` command like this:\n",
      "\n",
      "```bash\n",
      "find . -type f \\( -name '*.txt' -o -name '*.text' \\) -mtime -30 -print0 | xargs -0 ls -l --color=auto\n",
      "```\n",
      "\n",
      "Here's a breakdown of the command:\n",
      "\n",
      "- `find .` starts searching for files in the current directory (`.`)\n",
      "- `-type f` looks for only regular files\n",
      "- `\\( -name '*.txt' -o -name '*.text' \\)` searches for files with extensions `.txt` and `.text`\n",
      "- `-mtime -30` finds files modified within the last 30 days (-30 is interpreted as \"less than or equal to -30 days\")\n",
      "- `-print0` prints a null byte (instead of spaces) between file names, which helps if any filenames contain spaces\n",
      "- `xargs -0 ls -l --color"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  8039.99 ms\n",
      "llama_print_timings:      sample time =   299.30 ms /   256 runs   (    1.17 ms per token,   855.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =   763.73 ms /    29 tokens (   26.34 ms per token,    37.97 tokens per second)\n",
      "llama_print_timings:        eval time = 12441.98 ms /   255 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_print_timings:       total time = 14198.82 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' To list all the text files (i.e., files with extension .txt) in the current directory that have been modified within the last 30 days, you can use the `find` command like this:\\n\\n```bash\\nfind . -type f \\\\( -name \\'*.txt\\' -o -name \\'*.text\\' \\\\) -mtime -30 -print0 | xargs -0 ls -l --color=auto\\n```\\n\\nHere\\'s a breakdown of the command:\\n\\n- `find .` starts searching for files in the current directory (`.`)\\n- `-type f` looks for only regular files\\n- `\\\\( -name \\'*.txt\\' -o -name \\'*.text\\' \\\\)` searches for files with extensions `.txt` and `.text`\\n- `-mtime -30` finds files modified within the last 30 days (-30 is interpreted as \"less than or equal to -30 days\")\\n- `-print0` prints a null byte (instead of spaces) between file names, which helps if any filenames contain spaces\\n- `xargs -0 ls -l --color'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Question: In bash, how do I list all the text files in the current directory that have been modified in the last month? Answer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.hub.langchain.com/commits/rlm/rag-prompt-default/?limit=100&offset=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/furyhawk/projects/llama2/rag.ipynb Cell 19\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/furyhawk/projects/llama2/rag.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m \u001b[39mimport\u001b[39;00m hub\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/furyhawk/projects/llama2/rag.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m QA_CHAIN_PROMPT \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39;49mpull(\u001b[39m\"\u001b[39;49m\u001b[39mrlm/rag-prompt-default\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchain/hub.py:80\u001b[0m, in \u001b[0;36mpull\u001b[0;34m(owner_repo_commit, api_url, api_key)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mPulls an object from the hub and returns it as a LangChain object.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39m:param api_key: The API key to use to authenticate with the LangChain Hub API.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     79\u001b[0m client \u001b[39m=\u001b[39m _get_client(api_url\u001b[39m=\u001b[39mapi_url, api_key\u001b[39m=\u001b[39mapi_key)\n\u001b[0;32m---> 80\u001b[0m resp: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mpull(owner_repo_commit)\n\u001b[1;32m     81\u001b[0m \u001b[39mreturn\u001b[39;00m loads(resp)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchainhub/client.py:251\u001b[0m, in \u001b[0;36mClient.pull\u001b[0;34m(self, owner_repo_commit)\u001b[0m\n\u001b[1;32m    249\u001b[0m owner, repo, commit_hash \u001b[39m=\u001b[39m parse_owner_repo_commit(owner_repo_commit)\n\u001b[1;32m    250\u001b[0m \u001b[39mif\u001b[39;00m commit_hash \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m commit_hash \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlatest\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 251\u001b[0m     commit_hash \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_latest_commit_hash(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mowner\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mrepo\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    252\u001b[0m     \u001b[39mif\u001b[39;00m commit_hash \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo commits found\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchainhub/client.py:176\u001b[0m, in \u001b[0;36mClient._get_latest_commit_hash\u001b[0;34m(self, repo_full_name)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_latest_commit_hash\u001b[39m(\u001b[39mself\u001b[39m, repo_full_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Optional[\u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 176\u001b[0m     commits_resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlist_commits(repo_full_name)\n\u001b[1;32m    177\u001b[0m     commits \u001b[39m=\u001b[39m commits_resp[\u001b[39m\"\u001b[39m\u001b[39mcommits\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    178\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(commits) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/langchainhub/client.py:154\u001b[0m, in \u001b[0;36mClient.list_commits\u001b[0;34m(self, repo_full_name, limit, offset)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlist_commits\u001b[39m(\u001b[39mself\u001b[39m, repo_full_name: \u001b[39mstr\u001b[39m, limit: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, offset: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[1;32m    150\u001b[0m     res \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\n\u001b[1;32m    151\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_url\u001b[39m}\u001b[39;00m\u001b[39m/commits/\u001b[39m\u001b[39m{\u001b[39;00mrepo_full_name\u001b[39m}\u001b[39;00m\u001b[39m/?limit=\u001b[39m\u001b[39m{\u001b[39;00mlimit\u001b[39m}\u001b[39;00m\u001b[39m&offset=\u001b[39m\u001b[39m{\u001b[39;00moffset\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m         headers\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_headers(),\n\u001b[1;32m    153\u001b[0m     )\n\u001b[0;32m--> 154\u001b[0m     res\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m res\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/langchain/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[39m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Server Error: \u001b[39m\u001b[39m{\u001b[39;00mreason\u001b[39m}\u001b[39;00m\u001b[39m for url: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.hub.langchain.com/commits/rlm/rag-prompt-default/?limit=100&offset=0"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "QA_CHAIN_PROMPT = hub.pull(\"rlm/rag-prompt-default\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
